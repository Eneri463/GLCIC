{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123d92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from random import randint\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e864d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 6\n",
    "imageHeight = 256\n",
    "imageWidth = 256\n",
    "imageChannels = 3\n",
    "epochs = 50\n",
    "pp = 70000 # количество изображений, которые будут использоваться для обучения/тестирования\n",
    "pathM = 'data/masks'\n",
    "pathMT = 'data/masks_test'\n",
    "pathI = 'data/faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7815f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# класс, создающий контекстный кодировщик и обучающий его\n",
    "class GLCIC:\n",
    "    \n",
    "    # обрезаем случайную часть изображения для локального дискриминатора\n",
    "    def randomCrop(self, imageTrue, imageFalse):\n",
    "        \n",
    "\n",
    "        imageShape = imageTrue.get_shape()\n",
    "        boxesTrue = []\n",
    "        boxesFalse = []\n",
    "        \n",
    "        for i in range(imageShape[0]):\n",
    "            \n",
    "            x1 = tf.random.uniform(shape=[], minval=0, maxval=imageShape[2]-self.cropWidth, dtype=tf.int32)\n",
    "            y1 = tf.random.uniform(shape=[], minval=0, maxval=imageShape[1]-self.cropHeight, dtype=tf.int32)\n",
    "            x2 = x1 + self.cropHeight\n",
    "            y2 = y1 + self.cropWidth\n",
    "        \n",
    "            boxesTrue.append([y1 / imageShape[1], x1 / imageShape[2], y2 / imageShape[1], x2 / imageShape[2]])\n",
    "            boxesFalse.append([y1 / imageShape[1], x1 / imageShape[2], y2 / imageShape[1], x2 / imageShape[2]])\n",
    "        \n",
    "        box_indices = [i for i in range(imageShape[0])]\n",
    "\n",
    "        newImageTrue = tf.image.crop_and_resize(image = imageTrue, boxes = boxesTrue,box_indices = box_indices, crop_size = [self.cropHeight,self.cropWidth])\n",
    "        newImageFalse = tf.image.crop_and_resize(image = imageFalse, boxes = boxesFalse,box_indices = box_indices, crop_size = [self.cropHeight,self.cropWidth])\n",
    "        \n",
    "        return newImageTrue, newImageFalse\n",
    "    \n",
    "    def __init__(self, trainData, testData, epochs, batchSize, imageHeight = 256, imageWidth = 256, imageChannels = 3):\n",
    "        \n",
    "        # ----- гиперпараметры обучения\n",
    "        \n",
    "        self.epochs = epochs                   # количество эпох\n",
    "        self.batchSize = batchSize             # размер одного батча\n",
    "        self.imageHeight = imageHeight         # высота изображения\n",
    "        self.imageWidth = imageWidth           # ширина изображения\n",
    "        self.imageChannels = imageChannels     # количество каналов в изображении\n",
    "\n",
    "        self.reducedHeight = 256     # высота восстанавливаемой области\n",
    "        self.reducedWidth = 256      # ширина восстанавливаемой области\n",
    "        self.cropHeight = 128     # высота восстанавливаемой области\n",
    "        self.cropWidth = 128      # ширина восстанавливаемой области\n",
    "        \n",
    "        # ----- объекты и данные, используемые при обучении\n",
    "        \n",
    "        # данные для обучения\n",
    "        self.trainData = trainData\n",
    "        self.testData = testData\n",
    "        \n",
    "        # исходное изображение, исходное изображение с повреждённой областью и маски\n",
    "        self.inputs =  tf.placeholder(tf.float32, [self.batchSize, self.imageHeight, self.imageWidth, self.imageChannels])\n",
    "        self.inputsDamaged =  tf.placeholder(tf.float32, [self.batchSize, self.imageHeight, self.imageWidth, self.imageChannels])\n",
    "        self.masks = tf.placeholder(tf.float32, [self.batchSize, self.imageHeight, self.imageWidth, self.imageChannels])\n",
    "        \n",
    "        # генератор\n",
    "        generator = gen(\"generator\")\n",
    "        \n",
    "        # дискриминатор\n",
    "        discriminator = disConcat(\"allDiscriminators\")\n",
    "        \n",
    "        self.Fake = generator(self.inputsDamaged)\n",
    "        \n",
    "        # закомментированное нужно, если reducedHeight/reducedWidth отличается от imageHeight/reducedWidth\n",
    "        # отправляется в дискриминаторы вместо inputs и fake\n",
    "        #self.reduceImputs = tf.image.resize_images(self.inputs, [self.reducedHeight, self.reducedWidth]) \n",
    "        #self.reduceFake = tf.image.resize_images(self.Fake, [self.reducedHeight, self.reducedWidth])\n",
    "        \n",
    "        self.cropTrue, self.cropFake = self.randomCrop(self.inputs, self.Fake)\n",
    "        \n",
    "        self.disTrue = discriminator(self.inputs, self.cropTrue)\n",
    "        self.disFake = discriminator(self.Fake, self.cropFake)\n",
    "        \n",
    "        self.disLoss = -tf.reduce_mean(tf.log(self.disTrue + 1e-6) + tf.log(1 - self.disFake + 1e-6))\n",
    "        \n",
    "        self.genLoss1 = tf.reduce_mean(tf.reduce_sum(tf.square(self.masks*(self.inputs - self.Fake)), [1, 2, 3]))\n",
    "        self.genLoss2 = (-0.0004)*tf.reduce_mean(tf.log(self.disFake + 1e-5)) + tf.reduce_mean(tf.reduce_sum(tf.square(self.inputs - self.Fake), [1, 2, 3]))\n",
    "        \n",
    "        self.disOptimizer = tf.train.AdamOptimizer(2e-4).minimize(self.disLoss, var_list=discriminator.get_var())\n",
    "        self.genOptimizer1 = tf.train.AdamOptimizer(2e-4).minimize(self.genLoss1, var_list=generator.get_var())\n",
    "        self.genOptimizer2 = tf.train.AdamOptimizer(2e-4).minimize(self.genLoss2, var_list=generator.get_var())\n",
    "        \n",
    "        self.costDis = tf.summary.scalar(\"disLoss\", self.disLoss)\n",
    "        self.costGen = tf.summary.scalar(\"genLoss\", self.genLoss2)\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.writerTest = tf.summary.FileWriter(\"./logs/test\")\n",
    "        self.writerTrain = tf.summary.FileWriter(\"./logs/train\")\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    # -------------------------------------------------------------- обучение\n",
    "    def train(self, i=0, whenSave = 1):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.writerTrain.add_graph(self.sess.graph)\n",
    "        self.writerTest.add_graph(self.sess.graph)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            im = []\n",
    "            im2 = []\n",
    "            \n",
    "            # ----- шаг обучения\n",
    "            for numberBatch in range(len(self.trainData)):\n",
    "                \n",
    "                im, damagedIm, mask = self.trainData[numberBatch]\n",
    "                \n",
    "                #self.sess.run(self.genOptimizer1, feed_dict={self.inputs: im, self.inputsDamaged: damagedIm, self.masks: mask})\n",
    "                self.sess.run(self.disOptimizer, feed_dict={self.inputs: im, self.inputsDamaged: damagedIm})\n",
    "                self.sess.run(self.genOptimizer2, feed_dict={self.inputs: im, self.inputsDamaged: damagedIm, self.masks: mask})\n",
    "            \n",
    "            # ----- вывод промежуточных результатов:\n",
    "            im2, damagedIm2, mask2 = self.testData[0]\n",
    "\n",
    "            summaryTrain, resLossDTrain, resLossGTrain = self.sess.run([self.merged, self.disLoss, self.genLoss2], feed_dict={self.inputs: im, self.inputsDamaged: damagedIm, self.masks: mask})\n",
    "\n",
    "            summaryTest, resLossDTest, resLossGTest = self.sess.run([self.merged, self.disLoss, self.genLoss2], feed_dict={self.inputs: im2, self.inputsDamaged: damagedIm2, self.masks: mask2})\n",
    "\n",
    "            self.writerTrain.add_summary(summaryTrain, i)\n",
    "            self.writerTest.add_summary(summaryTest, i)\n",
    "\n",
    "            print(\"Итерация \" + str(i) + \". D loss = \" + str(resLossDTrain) + \", D loss Test = \" + str(resLossDTest) + \", G loss = \" + str(resLossGTrain) + \", G loss Test = \" + str(resLossGTest) + \".\")\n",
    "\n",
    "            # ----- сохраняем параметры нейронки каждые whenSave эпох\n",
    "            if (epoch + 1) % 1 == 0:\n",
    "\n",
    "                resImage = self.sess.run(self.Fake, feed_dict={self.inputsDamaged: damagedIm2})\n",
    "                Image.fromarray(np.uint8(resImage[0]*255)).save(\"./Results//\" + str(i) + \".jpg\")\n",
    "                Image.fromarray(np.uint8(damagedIm2[0]*255)).save(\"./Results//\" + str(i) + \"_1.jpg\")\n",
    "                self.saver.save(self.sess, \"./save_para//para.ckpt\")\n",
    "\n",
    "            self.trainData.on_epoch_end()\n",
    "            self.testData.on_epoch_end()\n",
    "            i = i+1\n",
    "            \n",
    "    # -------------------------------------------------------------- восстановление данных\n",
    "    def restoreModel(self, pathMeta, path):\n",
    "\n",
    "        self.saver = tf.train.import_meta_graph(pathMeta)\n",
    "        self.saver.restore(self.sess, tf.train.latest_checkpoint(path))\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------- \n",
    "    # использование готовой модели для восстановления изображения:\n",
    "    def useModel(self, image):\n",
    "        \n",
    "        resImage = self.sess.run([self.outputs], feed_dict={self.inputsDamaged: image})\n",
    "        Image.fromarray(np.uint8(resImage[0][0]*255)).save(\"./Results.jpg\")\n",
    "        print(\"Результат сохранен\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9908246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# реализация слоёв нейронной сети \n",
    "\n",
    "# ----- свёртка\n",
    "def conv2D(name, inputs, filters, kSize, stride, padding):\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        W = tf.get_variable(\"W\", shape=[kSize, kSize, inputs.shape[-1], filters], initializer=tf.random_normal_initializer(0., 0.005))\n",
    "        b = tf.get_variable(\"b\", shape=[filters], initializer=tf.constant_initializer(0.))\n",
    "        \n",
    "        return  tf.math.add(tf.nn.conv2d(inputs, W, [1, stride, stride, 1], padding), b)\n",
    "\n",
    "    \n",
    "# ----- расширенная свёртка\n",
    "def dilatedConv2D(name, inputs, filters, kSize, dilation):\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        W = tf.get_variable(\"W\", shape=[kSize, kSize, inputs.shape[-1], filters], initializer=tf.random_normal_initializer(0., 0.005))\n",
    "        b = tf.get_variable(\"b\", shape=[filters], initializer=tf.constant_initializer(0.))\n",
    "        \n",
    "        return  tf.math.add(tf.nn.atrous_conv2d(inputs, W, dilation, padding='SAME'), b)\n",
    "\n",
    "# ----- обратная свёртка\n",
    "def unconv2D(name, inputs, filters, kSize, stride, padding, r = 2):\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        w = tf.get_variable(\"W\", shape=[kSize, kSize, filters, int(inputs.shape[-1])], initializer=tf.random_normal_initializer(0., 0.005))\n",
    "        b = tf.get_variable(\"b\", shape=[filters], initializer=tf.constant_initializer(0.))\n",
    "        \n",
    "        B = tf.shape(inputs)[0]\n",
    "        H = int(inputs.shape[1])\n",
    "        W = int(inputs.shape[2])\n",
    "        \n",
    "        return  tf.math.add(tf.nn.conv2d_transpose(inputs, w, [B, H*r, W*r, filters], [1, stride, stride, 1], padding), b)\n",
    "\n",
    "# ----- полносвязный слой / вектор \n",
    "def fullyConnected(name, inputs, filters):\n",
    "    \n",
    "    inputs = tf.layers.flatten(inputs)\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        W = tf.get_variable(\"W\", [int(inputs.shape[-1]), filters], initializer=tf.random_normal_initializer(0., 0.005))\n",
    "        b = tf.get_variable(\"b\", [filters], initializer=tf.constant_initializer(0.))\n",
    "    \n",
    "        return tf.math.add(tf.matmul(inputs, W), b)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# класс генератора\n",
    "class gen:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            \n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv1\", inputs, 64, 5, 1, \"SAME\")))\n",
    "            \n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv2\", model, 128, 3, 2, \"SAME\")))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv3\", model, 128, 3, 1, \"SAME\")))\n",
    "            \n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv4\", model, 256, 3, 2, \"SAME\")))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv5\", model, 256, 3, 1, \"SAME\")))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv6\", model, 256, 3, 1, \"SAME\")))\n",
    "            \n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(dilatedConv2D(\"dilConv1\", model, 256, 3, 2)))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(dilatedConv2D(\"dilConv2\", model, 256, 3, 4)))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(dilatedConv2D(\"dilConv3\", model, 256, 3, 8)))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(dilatedConv2D(\"dilConv4\", model, 256, 3, 16)))\n",
    "            \n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv7\", model, 256, 3, 1, \"SAME\")))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv8\", model, 256, 3, 1, \"SAME\")))\n",
    "            \n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(unconv2D(\"unconv1\", model, 128, 4, 2, \"SAME\")))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv9\", model, 128, 3, 1, \"SAME\")))\n",
    "            \n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(unconv2D(\"unconv2\", model, 64, 4, 2, \"SAME\")))\n",
    "            model = tf.nn.relu(tf.layers.batch_normalization(conv2D(\"conv10\", model, 32, 3, 1, \"SAME\")))\n",
    "            model = tf.nn.tanh(conv2D(\"conv11\", model, 3, 3, 1, \"SAME\"))\n",
    "    \n",
    "            return model\n",
    "\n",
    "    def get_var(self):\n",
    "        return  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.name)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# класс локального дискриминатора\n",
    "class disLocal:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv1\", inputs, 64, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv2\", model, 128, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv3\", model, 256, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv4\", model, 512, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv5\", model, 512, 5, 2, \"SAME\")))\n",
    "            model = fullyConnected(\"fc\", model, 1024)\n",
    "            \n",
    "            return model\n",
    "\n",
    "    def get_var(self):\n",
    "        return  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.name)\n",
    "\n",
    "    \n",
    "# -------------------------------------------------------------------\n",
    "# класс глобального дискриминатора\n",
    "class disGlobal:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv1\", inputs, 64, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv2\", model, 128, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv3\", model, 256, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv4\", model, 512, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv5\", model, 512, 5, 2, \"SAME\")))\n",
    "            model = tf.layers.batch_normalization(tf.nn.relu(conv2D(\"conv6\", model, 512, 5, 2, \"SAME\")))\n",
    "            model = fullyConnected(\"fc\", model, 1024)\n",
    "    \n",
    "            return model\n",
    "\n",
    "    def get_var(self):\n",
    "        return  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.name)\n",
    "\n",
    "    \n",
    "class disConcat():\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, inputsG, inputsL):\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            globalDis = disGlobal('global')\n",
    "            localDis = disLocal('local')\n",
    "            \n",
    "            output = tf.concat((globalDis(inputsG), localDis(inputsL)), 1)\n",
    "            output = tf.sigmoid(fullyConnected(\"fc\", output, 1))\n",
    "    \n",
    "            return output\n",
    "\n",
    "    def get_var(self):\n",
    "        return  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf2ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс, генерирующий тренировочные данные\n",
    "class createAugment():\n",
    "    \n",
    "    # --\n",
    "    # инициализация объекта класса\n",
    "    def __init__(self, imgs, masks, batch_size=10, dim=(128, 128), n_channels=3):\n",
    "        self.batch_size = batch_size  # размер батча\n",
    "        self.images = imgs            # исходное изображение\n",
    "        self.masks = masks            # маски изображений\n",
    "        self.dim = dim                # размер изображения\n",
    "        self.n_channels = n_channels  # количество каналов\n",
    "        self.on_epoch_end()           # генерация набора батчей\n",
    "    \n",
    "    # --\n",
    "    # результат: кол-во возможных батчей за эпоху\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.images) / self.batch_size))\n",
    "    \n",
    "    # --\n",
    "    # результат: взятие батча с заданным номером (индексом)\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        imageOrig, imageMasked, imageMasks = self.data_generation(indexes)\n",
    "        return imageOrig, imageMasked, imageMasks\n",
    "    \n",
    "    # --\n",
    "    # функция, повторяющаяся в конце каждой эпохи\n",
    "    # результат: новая совокупность индексов изображений для очередного батча\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.images))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    # --\n",
    "    # результат: батч данных, включающий в себя \n",
    "    # исходное изображени, маскированное изображение и маску\n",
    "    def data_generation(self, idxs):\n",
    "        \n",
    "        imageMasked = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # маскированное изображения\n",
    "        imageMasks = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # маски\n",
    "        imageOrig = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # изображение под маской\n",
    "\n",
    "        for i, idx in enumerate(idxs):\n",
    "            \n",
    "            image, masked_image, image_masks = self.createMask(self.images[idx].copy())\n",
    "            imageMasked[i,] = masked_image/255\n",
    "            imageOrig[i,] = image/255\n",
    "            imageMasks[i,] = image_masks/255\n",
    "            \n",
    "        return imageOrig, imageMasked, imageMasks\n",
    "    \n",
    "    # --\n",
    "    # поворот изображения\n",
    "    def imageRotate(self, img):\n",
    "        \n",
    "        angle = np.random.randint(1, 359)\n",
    "        M = cv2.getRotationMatrix2D((self.dim[0]//2, self.dim[1]//2), 45, 1.0)\n",
    "        rotated = cv2.warpAffine(img, M, self.dim)\n",
    "        \n",
    "        return rotated\n",
    "    \n",
    "    # --\n",
    "    # уменьшение изначальной маски\n",
    "    def imageResize(self, img):\n",
    "\n",
    "        background = np.full((self.dim[0], self.dim[1], self.n_channels), 0, np.uint8)\n",
    "\n",
    "        widthNew = np.random.randint(int(self.dim[0]/2), self.dim[0])\n",
    "        heightNew = np.random.randint(int(self.dim[1]/2), self.dim[1])\n",
    "        \n",
    "        imgNew = cv2.resize(img, (widthNew, heightNew))\n",
    "\n",
    "        xNew = np.random.randint(0, self.dim[0] - widthNew)\n",
    "        yNew = np.random.randint(0, self.dim[1] - heightNew)\n",
    "\n",
    "        background[yNew:yNew+heightNew,xNew:xNew+widthNew] = imgNew\n",
    "\n",
    "        return background\n",
    "    \n",
    "    # --\n",
    "    # добавляем дополнительные элементы\n",
    "    def imageDetails(self, mask):\n",
    "        \n",
    "        # генерируем количество линий-повреждений на рисунке\n",
    "        n_line = np.random.randint(1, 5)\n",
    "        \n",
    "        # рисуем линии\n",
    "        for i in range(n_line):\n",
    "            \n",
    "            # генерируем первую точку линии\n",
    "            x_start = np.random.randint(1, self.dim[0])\n",
    "            y_start = np.random.randint(1, self.dim[1])\n",
    "            \n",
    "            # генерируем вторую точку линии\n",
    "            x_finish = np.random.randint(1, self.dim[0])\n",
    "            y_finish = np.random.randint(1, self.dim[1])\n",
    "            \n",
    "            # определяем толщину линии\n",
    "            point = np.random.randint(1, 5)\n",
    "            \n",
    "            # рисуем линию между сгенерированными точками\n",
    "            cv2.line(mask, (x_start, y_start), (x_finish, y_finish), (255,255,255), point)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    # --\n",
    "    # маскируем входное изображение случайной маской повреждений\n",
    "    def createMask(self, image):\n",
    "        \n",
    "        randNumberOfMask = np.random.randint(0, len(self.masks)-1)\n",
    "        isRotate = np.random.randint(1, 10)\n",
    "        isResize = np.random.randint(1, 10)\n",
    "        \n",
    "        # маска, значение которой 255 в области, которую нужно заполнить\n",
    "        # 0 - в остальных областях\n",
    "        mask = (self.masks[randNumberOfMask].copy())\n",
    "        \n",
    "        if isResize%2 == 0:\n",
    "            mask = self.imageResize(mask)\n",
    "        \n",
    "        if isRotate%2 == 0:\n",
    "            mask = self.imageRotate(mask)\n",
    "          \n",
    "        \n",
    "        mask = self.imageDetails(mask)\n",
    "        \n",
    "        # делаем края маски более жесткими (чтобы пиксели маски не содержали значения, кроме 0 и 255)\n",
    "        mask2 = (mask//255)*255\n",
    "        \n",
    "        imageMasked = cv2.bitwise_and(image, cv2.bitwise_not(mask2)) + mask2\n",
    "        \n",
    "        return image, imageMasked, mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b353dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = os.listdir(pathI) \n",
    "masksPaths = os.listdir(pathM) \n",
    "masksPathsTest = os.listdir(pathMT)\n",
    "images = np.empty((pp, imageHeight, imageWidth, imageChannels), dtype='uint8')\n",
    "masks = np.empty((len(masksPaths), imageHeight, imageWidth, imageChannels), dtype='uint8')\n",
    "masksTest = np.empty((len(masksPathsTest), imageHeight, imageWidth, imageChannels), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1946c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = imagePaths[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "055d6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for path in imagePaths:\n",
    "    img = Image.open(os.path.join(pathI, path))\n",
    "    img = img.resize((imageHeight,imageWidth))\n",
    "    images[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    i = i+1\n",
    "    if i == pp:\n",
    "        break\n",
    "\n",
    "i = 0\n",
    "for path in masksPaths:\n",
    "    img = Image.open(os.path.join(pathM, path))\n",
    "    img = img.resize((imageHeight,imageWidth))\n",
    "    masks[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    i = i+1\n",
    "\n",
    "i = 0    \n",
    "for path in masksPathsTest:\n",
    "    img = Image.open(os.path.join(pathMT, path))\n",
    "    img = img.resize((imageHeight,imageWidth))\n",
    "    masksTest[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    i = i+1\n",
    "    \n",
    "trainData = createAugment(images[0:int(pp*0.9)], masks, batchSize, dim = [imageHeight, imageWidth])\n",
    "testData = createAugment(images[int(pp*0.9):], masksTest, batchSize, dim = [imageHeight, imageWidth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2112a268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eneri\\anaconda3\\envs\\pleaseWork\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:423: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Eneri\\anaconda3\\envs\\pleaseWork\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\Eneri\\anaconda3\\envs\\pleaseWork\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:513: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "network = GLCIC(trainData, testData, epochs, batchSize, imageHeight, imageWidth, imageChannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909a7555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save_para\\para.ckpt\n"
     ]
    }
   ],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "network.restoreModel('./save_para//para.ckpt.meta', './save_para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87883067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация 152. D loss = 13.81551, D loss Test = 13.81551, G loss = 637.33356, G loss Test = 485.5195.\n",
      "Итерация 153. D loss = 13.81551, D loss Test = 13.81551, G loss = 142.31224, G loss Test = 289.32666.\n",
      "Итерация 154. D loss = 13.81551, D loss Test = 13.81551, G loss = 220.09103, G loss Test = 456.36334.\n",
      "Итерация 155. D loss = 13.81551, D loss Test = 13.81551, G loss = 349.235, G loss Test = 310.65802.\n",
      "Итерация 156. D loss = 13.81551, D loss Test = 13.81551, G loss = 147.31256, G loss Test = 690.2611.\n",
      "Итерация 157. D loss = 13.81551, D loss Test = 13.81551, G loss = 338.33643, G loss Test = 356.46838.\n",
      "Итерация 158. D loss = 13.81551, D loss Test = 13.81551, G loss = 680.52637, G loss Test = 805.37573.\n",
      "Итерация 159. D loss = 13.81551, D loss Test = 13.81551, G loss = 298.2708, G loss Test = 830.38837.\n",
      "Итерация 160. D loss = 13.81551, D loss Test = 13.81551, G loss = 315.76913, G loss Test = 266.2445.\n",
      "Итерация 161. D loss = 13.81551, D loss Test = 13.81551, G loss = 213.99185, G loss Test = 334.97495.\n",
      "Итерация 162. D loss = 13.81551, D loss Test = 13.81551, G loss = 272.1488, G loss Test = 691.57245.\n",
      "Итерация 163. D loss = 13.81551, D loss Test = 13.81551, G loss = 140.4296, G loss Test = 993.83734.\n",
      "Итерация 164. D loss = 13.81551, D loss Test = 13.81551, G loss = 619.47534, G loss Test = 327.61414.\n",
      "Итерация 165. D loss = 13.81551, D loss Test = 13.81551, G loss = 709.1213, G loss Test = 389.94064.\n",
      "Итерация 166. D loss = 13.81551, D loss Test = 13.81551, G loss = 165.18692, G loss Test = 253.75156.\n",
      "Итерация 167. D loss = 13.81551, D loss Test = 13.81551, G loss = 1036.3212, G loss Test = 1048.8744.\n",
      "Итерация 168. D loss = 13.81551, D loss Test = 13.81551, G loss = 351.78598, G loss Test = 1242.7211.\n",
      "Итерация 169. D loss = 13.81551, D loss Test = 13.81551, G loss = 261.0065, G loss Test = 551.185.\n",
      "Итерация 170. D loss = 13.81551, D loss Test = 13.81551, G loss = 210.11629, G loss Test = 393.0935.\n",
      "Итерация 171. D loss = 13.81551, D loss Test = 13.81551, G loss = 305.33646, G loss Test = 582.1095.\n",
      "Итерация 172. D loss = 13.81551, D loss Test = 13.81551, G loss = 346.82184, G loss Test = 490.10678.\n",
      "Итерация 173. D loss = 13.81551, D loss Test = 13.81551, G loss = 305.03152, G loss Test = 588.9584.\n",
      "Итерация 174. D loss = 13.81551, D loss Test = 13.81551, G loss = 344.95383, G loss Test = 642.5975.\n",
      "Итерация 175. D loss = 13.81551, D loss Test = 13.81551, G loss = 385.83908, G loss Test = 434.87408.\n",
      "Итерация 176. D loss = 13.81551, D loss Test = 13.81551, G loss = 258.5386, G loss Test = 276.3864.\n",
      "Итерация 177. D loss = 13.81551, D loss Test = 13.81551, G loss = 457.07477, G loss Test = 771.8274.\n",
      "Итерация 178. D loss = 13.81551, D loss Test = 13.81551, G loss = 146.11963, G loss Test = 680.28723.\n",
      "Итерация 179. D loss = 13.81551, D loss Test = 13.81551, G loss = 256.3382, G loss Test = 949.3032.\n",
      "Итерация 180. D loss = 13.81551, D loss Test = 13.81551, G loss = 192.44948, G loss Test = 572.9785.\n",
      "Итерация 181. D loss = 13.81551, D loss Test = 13.81551, G loss = 257.32993, G loss Test = 2026.4662.\n",
      "Итерация 182. D loss = 13.81551, D loss Test = 13.81551, G loss = 313.5552, G loss Test = 505.03845.\n",
      "Итерация 183. D loss = 13.81551, D loss Test = 13.81551, G loss = 185.37202, G loss Test = 691.2817.\n",
      "Итерация 184. D loss = 13.81551, D loss Test = 13.81551, G loss = 242.17091, G loss Test = 457.60583.\n",
      "Итерация 185. D loss = 13.81551, D loss Test = 13.81551, G loss = 135.01031, G loss Test = 432.70654.\n",
      "Итерация 186. D loss = 13.81551, D loss Test = 13.81551, G loss = 233.56703, G loss Test = 793.61566.\n",
      "Итерация 187. D loss = 13.81551, D loss Test = 13.81551, G loss = 357.07568, G loss Test = 530.4132.\n",
      "Итерация 188. D loss = 13.81551, D loss Test = 13.81551, G loss = 373.3307, G loss Test = 528.24786.\n",
      "Итерация 189. D loss = 13.81551, D loss Test = 13.81551, G loss = 664.79333, G loss Test = 583.39307.\n",
      "Итерация 190. D loss = 13.81551, D loss Test = 13.81551, G loss = 374.3457, G loss Test = 313.61203.\n",
      "Итерация 191. D loss = 13.81551, D loss Test = 13.81551, G loss = 183.006, G loss Test = 571.7748.\n",
      "Итерация 192. D loss = 13.81551, D loss Test = 13.81551, G loss = 198.60512, G loss Test = 334.97748.\n",
      "Итерация 193. D loss = 13.81551, D loss Test = 13.81551, G loss = 263.0849, G loss Test = 527.32983.\n",
      "Итерация 194. D loss = 13.81551, D loss Test = 13.81551, G loss = 115.52593, G loss Test = 307.9883.\n",
      "Итерация 195. D loss = 13.81551, D loss Test = 13.81551, G loss = 200.5584, G loss Test = 557.70355.\n",
      "Итерация 196. D loss = 13.81551, D loss Test = 13.81551, G loss = 306.21014, G loss Test = 275.28564.\n",
      "Итерация 197. D loss = 13.81551, D loss Test = 13.81551, G loss = 314.71448, G loss Test = 1295.5072.\n",
      "Итерация 198. D loss = 13.81551, D loss Test = 13.81551, G loss = 208.43324, G loss Test = 405.54828.\n",
      "Итерация 199. D loss = 13.81551, D loss Test = 13.81551, G loss = 285.31677, G loss Test = 868.48236.\n",
      "Итерация 200. D loss = 13.81551, D loss Test = 13.81551, G loss = 300.27893, G loss Test = 569.30585.\n",
      "Итерация 201. D loss = 13.81551, D loss Test = 13.81551, G loss = 330.28754, G loss Test = 811.0127.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    network.train(152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a414d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
